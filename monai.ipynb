{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d72e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ece1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.utils import first, set_determinism, ensure_tuple_rep, look_up_option, optional_import, progress_bar, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    "    Transform,\n",
    "    AsDiscrete,\n",
    "    RandFlipd,\n",
    "    RandShiftIntensityd,\n",
    "    RandRotate90d,\n",
    "    EnsureTyped,\n",
    "    MapTransform,\n",
    "    ResizeWithPadOrCropd,\n",
    "    CropForeground,\n",
    "    Resize,\n",
    "    RandAffined\n",
    ")\n",
    "\n",
    "from monai.networks.nets import SwinUNETR, UNet,SegResNet\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.layers import Norm, DropPath, trunc_normal_\n",
    "from monai.networks.blocks import MLPBlock as Mlp\n",
    "from monai.networks.blocks import PatchEmbed, UnetOutBlock, UnetrBasicBlock, UnetrUpBlock\n",
    "from monai.networks import normal_init\n",
    "from monai.metrics import DiceMetric, MeanIoU, HausdorffDistanceMetric\n",
    "from monai.losses import DiceLoss,  DiceCELoss ,GeneralizedDiceLoss,MaskedDiceLoss,DiceFocalLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import ThreadDataLoader, CacheDataset, DataLoader, load_decathlon_datalist, Dataset, decollate_batch, set_track_meta\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######from main.aa import SegResNet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "from typing import Optional, Sequence, Tuple, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from torch.nn import LayerNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#from __future__ import annotations\n",
    "\n",
    "#from collections.abc import Sequence\n",
    "\n",
    "#import numpy as np\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "\n",
    "#from monai.networks.blocks.segresnet_block import ResBlock, get_conv_layer, get_upsample_layer\n",
    "#from monai.networks.layers.factories import Dropout\n",
    "#from monai.networks.layers.utils import get_act_layer, get_norm_layer\n",
    "from monai.utils import UpsampleMode\n",
    "#__all__ = [\"SegResNet\", \"SegResNetVAE\"]\n",
    "from monai.transforms import LoadImaged, AddChanneld, Compose, Resized\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = \"savedmodel\"\n",
    "#root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "set_determinism(seed=0)\n",
    "\n",
    "data_dir = \"../MONAI\"\n",
    "train_images1 = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTr1\", \"*.nii.gz\")))\n",
    "train_images2 = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTr2\", \"*.nii.gz\")))\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
    "\n",
    "\n",
    "\n",
    "data_dicts = [\n",
    "    {\"image1\": image1_name, \"image2\": image2_name, \"label\": label_name}\n",
    "    for image1_name, image2_name, label_name in zip(train_images1, train_images2, train_labels)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#train_files, val_files = data_dicts[:-5], data_dicts[-5:]\n",
    "train_files, val_files = data_dicts[:-8], data_dicts[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c657766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image1\",\"image2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image1\",\"image2\", \"label\"]),\n",
    "        #ScaleIntensityRanged(\n",
    "            #keys=[\"image\"], a_min=0, a_max=1,\n",
    "            #b_min=0.0, b_max=1.0, clip=True,\n",
    "        #),\n",
    "        \n",
    "        #CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image1\",\"image2\", \"label\"], axcodes=\"RAS\"),\n",
    "        #Resized(\n",
    "            #keys=[\"image1\", \"image2\", \"label\"],\n",
    "            #spatial_size=(112,112,64),\n",
    "            #mode=['bilinear','bilinear','nearest']\n",
    "        #),\n",
    "        Spacingd(keys=[\"image1\",\"image2\", \"label\"], pixdim=(\n",
    "            1.0, 1.0, 1.0), mode=(\"bilinear\",\"bilinear\", \"nearest\")),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image1\",\"image2\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            #spatial_size=(112, 112, 112),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=18,\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        # user can also add other random transforms\n",
    "        # RandAffined(\n",
    "        #     keys=['image', 'label'],\n",
    "        #     mode=('bilinear', 'nearest'),\n",
    "        #     prob=1.0, spatial_size=(96, 96, 96),\n",
    "        #     rotate_range=(0, 0, np.pi/15),\n",
    "        #     scale_range=(0.1, 0.1, 0.1)),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image1\",\"image2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image1\",\"image2\", \"label\"]),\n",
    "        #ScaleIntensityRanged(\n",
    "            #keys=[\"image\"], a_min=0, a_max=180,\n",
    "            #b_min=0.0, b_max=1.0, clip=True,\n",
    "        #),\n",
    "        #CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        #CropForegroundd(keys=[\"image\", \"label\"], source_key=\"label\", margin=64),\n",
    "        Orientationd(keys=[\"image1\",\"image2\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image1\",\"image2\", \"label\"], pixdim=(\n",
    "            1.0, 1.0, 1.0), mode=(\"bilinear\",\"bilinear\", \"nearest\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a871d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "#print(check_data[\"image1\"].size())\n",
    "image1,image2, label = (check_data[\"image1\"][0][0],check_data[\"image2\"][0][0], check_data[\"label\"][0][0])\n",
    "#print(f\"image1 shape: {image1.shape},image2 shape: {image2.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [:, :, 50]\n",
    "plt.figure(\"check\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"image1\")\n",
    "plt.imshow(image1[:, :, 30].detach().cpu(), cmap=\"gray\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"image2\")\n",
    "plt.imshow(image2[:, :, 30].detach().cpu(), cmap=\"gray\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, 30].detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a25e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "print(check_data[\"image1\"].size())\n",
    "image1,image2, label = (check_data[\"image1\"][0][0],check_data[\"image2\"][0][0], check_data[\"label\"][0][0])\n",
    "print(f\"image1 shape: {image1.shape},image2 shape: {image2.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [:, :, 50]\n",
    "plt.figure(\"check\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"image1\")\n",
    "plt.imshow(image1[:, :, 42].detach().cpu(), cmap=\"gray\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"image2\")\n",
    "plt.imshow(image2[:, :, 42].detach().cpu(), cmap=\"gray\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :,  42].detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbe138",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CacheDataset(\n",
    "    data=train_files, transform=train_transforms,\n",
    "    cache_rate=1.0, num_workers=4)\n",
    "# train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "    \n",
    "#val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)\n",
    "\n",
    "# torch.Tensor([B, D, H, W])\n",
    "# [121, 224, 224], [111, 224, 224]\n",
    "#↓ (Cache)Dataset\n",
    "# [5, 96, 96, 96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baf2b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "#train_loader = DataLoader(train_ds, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09685da",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_map = {\n",
    "    \"output231_dwi.nii.gz\": 80,\n",
    "}\n",
    "\n",
    "case_num = 1\n",
    "#img1_name = os.path.split(val_ds[case_num]['image1'].meta[\"filename_or_obj\"])[1]\n",
    "#img2_name = os.path.split(val_ds[case_num]['image2'].meta[\"filename_or_obj\"])[1]\n",
    "img_name = os.path.split(val_ds[case_num]['image1'].meta[\"filename_or_obj\"])[1]\n",
    "img1 = val_ds[case_num][\"image1\"]\n",
    "img2 = val_ds[case_num][\"image2\"]\n",
    "label = val_ds[case_num][\"label\"]\n",
    "img1_shape = img1.shape\n",
    "img2_shape = img2.shape\n",
    "label_shape = label.shape\n",
    "print(f\"image1 shape: {img1_shape},image2 shape: {img2_shape}, label shape: {label_shape}\")\n",
    "plt.figure(\"image\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"image1\")\n",
    "plt.imshow(img1[0, :, :, slice_map[img_name]].detach().cpu(), cmap=\"gray\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"image2\")\n",
    "plt.imshow(img2[0, :, :, slice_map[img_name]].detach().cpu(), cmap=\"gray\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[0, :, :, slice_map[img_name]].detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446deaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "#device = torch.device(\"cuda:0\")\n",
    "#model = UNet(\n",
    "    #spatial_dims=3,\n",
    "    #in_channels=1,\n",
    "    #out_channels=2,\n",
    "    #channels=(64, 128, 256, 512),\n",
    "    #strides=(2, 2, 2),\n",
    "    #num_res_units=2\n",
    "#).to(device)\n",
    "\n",
    "model = SegResNet(\n",
    "    spatial_dims=3,\n",
    "    init_filters=8,\n",
    "    in_channels=2,\n",
    "    out_channels=2,\n",
    "    dropout_prob=None,\n",
    "    act=('RELU', {'inplace': True}),\n",
    "    norm=('GROUP', {'num_groups': 8}),\n",
    "    norm_name='',\n",
    "    num_groups=8,\n",
    "    use_conv_final=True,\n",
    "    blocks_down=(1, 2, 2, 4),\n",
    "    blocks_up=(1, 1, 1),\n",
    "    upsample_mode=UpsampleMode.NONTRAINABLE)\n",
    "\n",
    "\n",
    "model.apply(normal_init)\n",
    "# input images are scaled to [0,1] so enforce the same of generated outputs\n",
    "model.conv_final.add_module(\"activation\", torch.nn.Sigmoid())\n",
    "#gen_net.model.add_module(\"activation\", torch.nn.Sigmoid())\n",
    "model = model.to(device)\n",
    "\n",
    "#loss_function = DiceLoss(to_onehot_y=True, softmax=True)DiceFocalLoss\n",
    "#loss_function = DiceLoss(include_background=True,to_onehot_y=True, softmax=True)\n",
    "#loss_function =GeneralizedDiceLoss(include_background=True,to_onehot_y=True,softmax=True,)#smooth_nr=1e-05)#smooth_nr=1e-05)\n",
    "#loss_function =DiceFocalLoss(to_onehot_y=True, softmax=True)\n",
    "#loss_function = MaskedDiceLoss(include_background=True,to_onehot_y=True, softmax=True)\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), 3e-5)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "#dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009989c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_epochs = 1000 #need 600 epochs to train a promising model\n",
    "val_interval = 5\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 600)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs1,inputs2, labels = (\n",
    "            batch_data[\"image1\"].to(device),\n",
    "            batch_data[\"image2\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        x = torch.cat([inputs1, inputs2], dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs1,val_inputs2, val_labels = (\n",
    "                    val_data[\"image1\"].to(device),\n",
    "                    val_data[\"image2\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                x = torch.cat([val_inputs1, val_inputs2], dim=1)\n",
    "                #roi_size = (192, 192, 128)\n",
    "                roi_size = (128, 128, 96)\n",
    "                sw_batch_size = 2\n",
    "                val_outputs = sliding_window_inference(\n",
    "                    x , roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "\n",
    "print(\n",
    "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "    f\"at epoch: {best_metric_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3990d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f3b5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_org_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image1\",\"image2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image1\",\"image2\", \"label\"]),\n",
    "        Orientationd(keys=[\"image1\",\"image2\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image1\",\"image2\",\"label\"], pixdim=(\n",
    "            1.0, 1.0, 1.0), mode=(\"bilinear\",\"bilinear\",\"nearest\")),\n",
    "        #ScaleIntensityRanged(\n",
    "            #keys=[\"image\"], a_min=0, a_max=5036,\n",
    "            #b_min=0.0, b_max=1.0, clip=True,\n",
    "        #),\n",
    "        #CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_org_ds = Dataset(\n",
    "    data=val_files, transform=val_org_transforms)\n",
    "val_org_loader = DataLoader(val_org_ds, batch_size=1, num_workers=4)\n",
    "\n",
    "post_transforms = Compose([\n",
    "    Invertd(\n",
    "        keys=\"pred\",\n",
    "        transform=val_org_transforms,\n",
    "        orig_keys=\"image\",\n",
    "        meta_keys=\"pred_meta_dict\",\n",
    "        orig_meta_keys=\"image_meta_dict\",\n",
    "        meta_key_postfix=\"meta_dict\",\n",
    "        nearest_interp=False,\n",
    "        to_tensor=True,\n",
    "        device=\"cpu\",\n",
    "    ),\n",
    "    AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
    "    AsDiscreted(keys=\"label\", to_onehot=2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e609080",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_data in val_org_loader:\n",
    "        val_inputs1 = val_data[\"image1\"].to(device)\n",
    "        val_inputs2 = val_data[\"image2\"].to(device)\n",
    "        \n",
    "        x = torch.cat([val_inputs1, val_inputs2], dim=1).to(device)\n",
    "        #roi_size = (192, 192, 128)\n",
    "        #roi_size = (128, 128, 96)\n",
    "        roi_size = (112, 112, 96)\n",
    "        sw_batch_size = 4\n",
    "        val_data[\"pred\"] = sliding_window_inference(\n",
    "            x, roi_size, sw_batch_size, model)\n",
    "        val_data = [post_transforms(i) for i in decollate_batch(val_data)]\n",
    "        val_outputs, val_labels = from_engine([\"pred\", \"label\"])(val_data)\n",
    "        # compute metric for current iteration\n",
    "        dice_metric=DiceMetric(include_background=False, reduction=\"mean\")\n",
    "        jaccard_metric = MeanIoU(include_background=False, reduction=\"mean\")\n",
    "        hd = HausdorffDistanceMetric(include_background=False, reduction=\"mean\")\n",
    "        \n",
    "        #print(type(val_outputs))\n",
    "        #print(type(val_labels))\n",
    "        #  [Tensor([],device='cuda:0')] -> Tensor([],device='cuda:0') -> Tensor([],device='cpu') ->[[Tensor([],device='cpu)]]\n",
    "        dice_metric(y_pred=[val_outputs[0].cpu()], y=[val_labels[0]])\n",
    "        jaccard_metric(y_pred=[val_outputs[0].cpu()], y=[val_labels[0]])\n",
    "        hd(y_pred=[val_outputs[0].cpu()], y=[val_labels[0]])\n",
    "        \n",
    "        #dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "        #jaccard_metric(y_pred=val_outputs, y=val_labels)\n",
    "        #hd(y_pred=val_outputs, y=val_labels)\n",
    "        \n",
    "        \n",
    "    #metric_org_dsc = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "    #metric_org_jsc = jaccard_metric(y_pred=val_outputs, y=val_labels)\n",
    "    #metric_org_hd = hd(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "\n",
    "    # aggregate the final mean dice result\n",
    "    metric_org_dsc = dice_metric.aggregate().item()\n",
    "    metric_org_jsc = jaccard_metric.aggregate().item()\n",
    "    metric_org_hd = hd.aggregate().item()\n",
    "    # reset the status for next validation round\n",
    "    dice_metric.reset()\n",
    "    jaccard_metric.reset()\n",
    "    hd.reset()\n",
    "\n",
    "print(\"Metric on original image spacing: \", metric_org_dsc)\n",
    "print(\"Metric on original image spacing: \", metric_org_jsc)\n",
    "print(\"Metric on original image spacing: \", metric_org_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7ea32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images1 = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTs1\", \"*.nii.gz\")))\n",
    "test_images2 = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTs2\", \"*.nii.gz\")))\n",
    "test_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labelsTs\", \"*.nii.gz\")))\n",
    "#test_image = [{\"image\": image} for image in test_images]\n",
    "#test_label = [{\"label\": image} for image in test_labels]\n",
    "test_files = [\n",
    "    {\"image1\": image1_name,\"image2\": image2_name, \"label\": label_name}\n",
    "    for image1_name,image2_name, label_name in zip(test_images1,test_images2, test_labels)\n",
    "]\n",
    "\n",
    "test_org_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image1\",\"image2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image1\",\"image2\", \"label\"]),\n",
    "        Orientationd(keys=[\"image1\",\"image2\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image1\",\"image2\",\"label\"], pixdim=(\n",
    "            1.0, 1.0, 1.0), mode=(\"bilinear\",\"bilinear\",\"nearest\")),\n",
    "        #ScaleIntensityRanged(\n",
    "            #keys=[\"image\"], a_min=0, a_max=5036,\n",
    "            #b_min=0.0, b_max=1.0, clip=True,\n",
    "        #),\n",
    "        #CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_org_ds = Dataset(\n",
    "    data=test_files, transform=test_org_transforms)\n",
    "\n",
    "test_org_loader = DataLoader(test_org_ds, batch_size=1, num_workers=4)\n",
    "\n",
    "\n",
    "class ReverseLabels:\n",
    "    def __call__(self, data):\n",
    "        data[\"pred\"] = 1 - data[\"pred\"]  # セグメンテーション領域と背景の値を反転\n",
    "        return data\n",
    "\n",
    "\n",
    "post_transforms = Compose([\n",
    "    Invertd(\n",
    "        keys=\"pred\",\n",
    "        transform=test_org_transforms,\n",
    "        orig_keys=\"image\",\n",
    "        meta_keys=\"pred_meta_dict\",\n",
    "        orig_meta_keys=\"image_meta_dict\",\n",
    "        meta_key_postfix=\"meta_dict\",\n",
    "        nearest_interp=False,\n",
    "        to_tensor=True,\n",
    "        device=\"cpu\",\n",
    "    ),\n",
    "    #ReverseLabels(),\n",
    "    AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
    "    SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=\"../seg/out\", output_postfix=\"seg\", resample=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86269ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "dice_scores = []\n",
    "jaccard_scores = []\n",
    "hausdorff_distances = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    with open(\"result.txt\", \"w\") as file:\n",
    "        for idx, test_data in enumerate(test_org_loader):\n",
    "            test_inputs1 = test_data[\"image1\"].to(device)\n",
    "            test_inputs2 = test_data[\"image2\"].to(device)\n",
    "            x = torch.cat([test_inputs1, test_inputs2], dim=1)\n",
    "            #roi_size = (192, 192, 128)\n",
    "            #roi_size = (112, 112, 96)\n",
    "            roi_size = (128, 128, 112)\n",
    "            sw_batch_size = 1\n",
    "            test_data[\"pred\"] = sliding_window_inference(x, roi_size, sw_batch_size, model)\n",
    "            test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n",
    "            test_outputs, test_raw_labels = from_engine([\"pred\", \"label\"])(test_data)\n",
    "\n",
    "            plt.figure(\"check\", (18, 6))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(test_inputs1[0, 0, :, :, 10].detach().cpu().numpy(), cmap=\"gray\")\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(test_inputs2[0, 0, :, :, 10].detach().cpu().numpy(), cmap=\"gray\")\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(test_outputs[0].detach().cpu()[1, :, :, 10], cmap=\"gray\")\n",
    "\n",
    "            dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "            jaccard_metric = MeanIoU(include_background=False, reduction=\"mean\")\n",
    "            hd = HausdorffDistanceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "            dice_metric(y_pred=[test_outputs[0].cpu()], y=test_raw_labels)\n",
    "            jaccard_metric(y_pred=[test_outputs[0].cpu()], y=test_raw_labels)\n",
    "            hd(y_pred=[test_outputs[0].cpu()], y=test_raw_labels)\n",
    "\n",
    "            dice_score = dice_metric.aggregate().item()\n",
    "            jaccard_score = jaccard_metric.aggregate().item()\n",
    "            hausdorff_distance = hd.aggregate().item()\n",
    "\n",
    "            dice_scores.append(dice_score)\n",
    "            jaccard_scores.append(jaccard_score)\n",
    "            hausdorff_distances.append(hausdorff_distance)\n",
    "\n",
    "            file.write(f\"Image {idx + 1} - Dice: {dice_score:.4f}, Jaccard: {jaccard_score:.4f}, Hausdorff Distance: {hausdorff_distance:.4f}\\n\")\n",
    "\n",
    "            dice_metric.reset()\n",
    "            jaccard_metric.reset()\n",
    "            hd.reset()\n",
    "\n",
    "        avg_dice = sum(dice_scores) / len(dice_scores)\n",
    "        std_dice = torch.tensor(dice_scores).std()\n",
    "\n",
    "        avg_jaccard = sum(jaccard_scores) / len(jaccard_scores)\n",
    "        std_jaccard = torch.tensor(jaccard_scores).std()\n",
    "\n",
    "        avg_hausdorff = sum(hausdorff_distances) / len(hausdorff_distances)\n",
    "        std_hausdorff = torch.tensor(hausdorff_distances).std()\n",
    "\n",
    "        file.write(f\"Avg Dice: {avg_dice:.4f}, Std Dice: {std_dice:.4f}\\n\")\n",
    "        file.write(f\"Avg Jaccard: {avg_jaccard:.4f}, Std Jaccard: {std_jaccard:.4f}\\n\")\n",
    "        file.write(f\"Avg Hausdorff Distance: {avg_hausdorff:.4f}, Std Hausdorff Distance: {std_hausdorff:.4f}\\n\")\n",
    "\n",
    "print(\"Metric on original image spacing: \", avg_dice)\n",
    "print(\"Metric on original image spacing: \", avg_jaccard)\n",
    "print(\"Metric on original image spacing: \", avg_hausdorff)\n",
    "print(\"Results saved to result.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b9fe7f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5a5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8a8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca0ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
